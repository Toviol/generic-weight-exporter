# -*- coding: utf-8 -*-
"""train_SNN_NMNIST_ON_OFF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YcQ3Zw7LnhIwW1Uv-DDsC1EuDmJX_551

# Introduction
In this tutorial, you will:
* Learn how spiking neurons are implemented as a recurrent network
* Understand backpropagation through time, and the associated challenges in SNNs such as the non-differentiability of spikes
* Train a fully-connected network on the static MNIST dataset

<!-- * Implement various backprop strategies:
  * Backpropagation Through Time
  * Truncated-Backpropagation Through Time
  * Real-Time Recurrent Learning -->

>Part of this tutorial was inspired by Friedemann Zenke's extensive work on SNNs. Check out his repo on surrogate gradients [here](https://github.com/fzenke/spytorch), and a favourite paper of mine: E. O. Neftci, H. Mostafa, F. Zenke, [Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-based optimization to spiking neural networks.](https://ieeexplore.ieee.org/document/8891809) IEEE Signal Processing Magazine 36, 51–63.

At the end of the tutorial, a basic supervised learning algorithm will be implemented. We will use the original static MNIST dataset and train a multi-layer fully-connected spiking neural network using gradient descent to perform image classification.

If running in Google Colab:
* You may connect to GPU by checking `Runtime` > `Change runtime type` > `Hardware accelerator: GPU`
* Next, install the latest PyPi distribution of snnTorch by clicking into the following cell and pressing `Shift+Enter`.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install snntorch

# Commented out IPython magic to ensure Python compatibility.
#  %pip install torchvision

# imports
import snntorch as snn
from snntorch import spikeplot as splt
from snntorch import spikegen

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import matplotlib.pyplot as plt
import numpy as np
import itertools

from snntorch import utils

seed = 0
np.random.seed(seed)
torch.manual_seed(seed)

print(f"Is CUDA supported by this system?{torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")

# Storing ID of current CUDA device
cuda_id = torch.cuda.current_device()
print(f"ID of current CUDA device:{torch.cuda.current_device()}")

print(f"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}")

# Leaky neuron model, overriding the backward pass with a custom function
class LeakySurrogate(nn.Module):
  def __init__(self, beta, threshold=1.0):
      super(LeakySurrogate, self).__init__()

      # initialize decay rate beta and threshold
      self.beta = beta
      self.threshold = threshold
      self.spike_gradient = self.ATan.apply

  # the forward function is called each time we call Leaky
  def forward(self, input_, mem):
    spk = self.spike_gradient((mem-self.threshold))  # call the Heaviside function
    reset = (self.beta * spk * self.threshold).detach() # remove reset from computational graph
    mem = self.beta * mem + input_ - reset # Eq (1)
    return spk, mem

  # Forward pass: Heaviside function
  # Backward pass: Override Dirac Delta with the ArcTan function
  @staticmethod
  class ATan(torch.autograd.Function):
      @staticmethod
      def forward(ctx, mem):
          spk = (mem > 0).float() # Heaviside on the forward pass: Eq(2)
          ctx.save_for_backward(mem)  # store the membrane for use in the backward pass
          return spk

      @staticmethod
      def backward(ctx, grad_output):
          (mem,) = ctx.saved_tensors  # retrieve the membrane potential
          grad = 1 / (1 + (np.pi * mem).pow_(2)) * grad_output # Eqn 5
          return grad

"""Note that the reset mechanism is detached from the computational graph, as the surrogate gradient should only be applied to $\partial S/\partial U$, and not $\partial R/\partial U$.

The above neuron is instantiated using:
"""

lif1 = LeakySurrogate(beta=0.9)

"""This neuron can be simulated using a for-loop, just as in previous tutorials, while PyTorch's automatic differentation (autodiff) mechanism keeps track of the gradient in the background.

Alternatively, the same thing can be accomplished by calling the `snn.Leaky` neuron.
In fact, every time you call any neuron model from snnTorch, the *ATan* surrogate gradient is applied to it by default:
"""

lif1 = snn.Leaky(beta=0.9)

"""If you would like to explore how this neuron behaves, then refer to [Tutorial 3](https://snntorch.readthedocs.io/en/latest/tutorials/index.html).

# 4. Setting up the Loss / Output Decoding
In a conventional, non-spiking neural network, a supervised, multi-class classification problem takes the neuron with the highest activation and treats that as the predicted class.

In a spiking neural net, there are several options to interpreting the output spikes. The most common approaches are:
* **Rate coding:** Take the neuron with the highest firing rate (or spike count) as the predicted class
* **Latency coding:** Take the neuron that fires *first* as the predicted class

This might feel familiar to [Tutorial 1 on neural encoding](https://snntorch.readthedocs.io/en/latest/tutorials/index.html). The difference is that, here, we are interpreting (decoding) the output spikes, rather than encoding/converting raw input data into spikes.

Let's focus on a rate code. When input data is passed to the network, we want the correct neuron class to emit the most spikes over the course of the simulation run. This then corresponds to the highest average firing frequency. One way to achieve this is to increase the membrane potential of the correct class to $U>U_{\rm thr}$, and that of incorrect classes to $U<U_{\rm thr}$. Applying the target to $U$ serves as a proxy for modulating spiking behavior from $S$.

This can be implemented by taking the softmax of the membrane potential for output neurons, where $C$ is the number of output classes:

$$p_i[t] = \frac{e^{U_i[t]}}{\sum_{j=0}^{C}e^{U_j[t]}} \tag{8}$$

The cross-entropy between $p_i$ and the target $y_i \in \{0,1\}^C$, which is a one-hot target vector, is obtained using:

$$\mathcal{L}_{CE}[t] = -\sum_{i=0}^Cy_i{\rm log}(p_i[t]) \tag{9}$$

The practical effect is that the membrane potential of the correct class is encouraged to increase while those of incorrect classes are reduced. In effect, this means the correct class is encouraged to fire at all time steps, while incorrect classes are suppressed at all steps. This may not be the most efficient implementation of an SNN, but it is among the simplest.

This target is applied at every time step of the simulation, thus also generating a loss at every step. These losses are then summed together at the end of the simulation:

$$\mathcal{L}_{CE} = \sum_t\mathcal{L}_{CE}[t] \tag{10}$$

This is just one of many possible ways to apply a loss function to a spiking neural network. A variety of approaches are available to use in snnTorch (in the module `snn.functional`), and will be the subject of a future tutorial.

With all of the background theory having been taken care of, let’s finally dive into
training a fully-connected spiking neural net.

# 5. Setting up the Neuromorphic MNIST Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tonic

import tonic
import tonic.transforms as transforms

dtype = torch.float
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")

num_steps = 10

sensor_size = tonic.datasets.NMNIST.sensor_size
transform = transforms.Compose(
    [
        transforms.ToFrame(sensor_size=sensor_size, n_time_bins=num_steps),
    ]
)

train_set = tonic.datasets.NMNIST(save_to="data/nmnist", train=True, transform=transform)
test_set = tonic.datasets.NMNIST(save_to="data/nmnist", train=False, transform=transform)

batch_size = 128
# from torch.utils.data import DataLoader

# testloader = DataLoader(
#     testset,
#     batch_size=10,
#     collate_fn=tonic.collation.PadTensors(batch_first=True),
# )

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=tonic.collation.PadTensors(batch_first=False), drop_last=True)

test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, collate_fn=tonic.collation.PadTensors(batch_first=False), drop_last=True)

# events, labels = train_loader[0]

"""If the above code blocks throws an error, e.g. the MNIST servers are down, then uncomment the following code instead."""

# # temporary dataloader if MNIST service is unavailable
# !wget www.di.ens.fr/~lelarge/MNIST.tar.gz
# !tar -zxvf MNIST.tar.gz

# mnist_train = datasets.MNIST(root = './', train=True, download=True, transform=transform)
# mnist_test = datasets.MNIST(root = './', train=False, download=True, transform=transform)

"""## *Save dataset as text (C array)"""

# with open('training_samples.h', 'w') as f, open('training_labels.h', 'w') as g:
#     f.write('float input_data[60000][784] = {')
#     g.write('int target_data[60000] = {')
#     for data, target in train_loader:
#         data = data.flatten()
#         target = target.item()
#         g.write(str(target) + ',')
#         f.write('{')
#         for i in range(len(data)):
#             f.write(str(data[i].item()))
#             if i != len(data) - 1:
#                 f.write(',')
#         f.write('},\n')
#     f.write('};')
#     g.write('};')

"""# 6. Define the Network"""

# Network Architecture
num_inputs = 34*34
num_hidden = 128
num_outputs = 10

# Temporal Dynamics
beta = 0.001

# surrogate function

spike_grad = snn.surrogate.atan(alpha=5)

net = nn.Sequential(nn.Linear(num_inputs, num_hidden, bias=False),
                    snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad, reset_mechanism='zero'),
                    # snn.Leaky(beta=beta, init_hidden=True, reset_mechanism='subtract'),
                    nn.Linear(num_hidden, num_outputs, bias=False),
                    snn.Leaky(beta=beta, init_hidden=True, spike_grad=spike_grad, reset_mechanism='zero', output=True)).to(device)
                    # snn.Leaky(beta=beta, init_hidden=True, reset_mechanism='subtract', output=True)).to(device)

def forward_pass(model, num_steps, data):
    spk_rec = []
    mem_rec = []
    utils.reset(net)

    for step in range(num_steps):
        # ON spikes
        spk, mem = net(data[step, :, 0, :])
        spk_rec.append(spk)
        mem_rec.append(mem)
        # OFF spikes
        spk, mem = net(data[step, :, 1, :])
        spk_rec.append(spk)
        mem_rec.append(mem)
    return torch.stack(spk_rec), torch.stack(mem_rec)

"""The code in the `forward()` function will only be called once the input argument `x` is explicitly passed into `net`.

* `fc1` applies a linear transformation to all input pixels from the MNIST dataset;
* `lif1` integrates the weighted input over time, emitting a spike if the threshold condition is met;
* `fc2` applies a linear transformation to the output spikes of `lif1`;
* `lif2` is another spiking neuron layer, integrating the weighted spikes over time.

# 7. Training the SNN

## 7.1 Accuracy Metric
Below is a function that takes a batch of data, counts up all the spikes from each neuron (i.e., a rate code over the simulation time), and compares the index of the highest count with the actual target. If they match, then the network correctly predicted the target.
"""

# pass data into the network, sum the spikes over time
# and compare the neuron with the highest number of spikes
# with the target

def print_batch_accuracy(data, targets, train=False):
    output, _ = forward_pass(net, num_steps, data)
    _, idx = output.sum(dim=0).max(1)
    acc = np.mean((targets == idx).detach().cpu().numpy())

    if train:
        print(f"Train set accuracy for a single minibatch: {acc*100:.2f}%")
    else:
        print(f"Test set accuracy for a single minibatch: {acc*100:.2f}%")

def train_printer():
    print(f"Epoch {epoch}, Iteration {iter_counter}")
    print(f"Train Set Loss: {loss_hist[counter]:.2f}")
    print(f"Test Set Loss: {test_loss_hist[counter]:.2f}")
    print_batch_accuracy(data, targets, train=True)
    print_batch_accuracy(test_data, test_targets, train=False)
    print("\n")

"""## 7.2 Loss Definition
The `nn.CrossEntropyLoss` function in PyTorch automatically handles taking the softmax of the output layer as well as generating a loss at the output.
"""

loss = nn.CrossEntropyLoss()

"""## 7.3 Optimizer
Adam is a robust optimizer that performs well on recurrent networks, so let's use that with a learning rate of $5\times10^{-4}$.
"""

optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))

"""## 7.5 Training Loop

Let's combine everything into a training loop. We will train for one epoch (though feel free to increase `num_epochs`), exposing our network to each sample of data once.
"""

from snntorch import utils

num_epochs = 20
loss_hist = []
test_loss_hist = []
counter = 0

# Outer training loop
for epoch in range(num_epochs):
    iter_counter = 0
    train_batch = iter(train_loader)

    # Minibatch training loop
    for data, targets in train_batch:
        data = data.to(device)
        data = data.reshape(data.size(0), data.size(1), data.size(2), -1).type(torch.float)
        data = torch.sign(data)
        targets = targets.to(device)

        # forward pass
        net.train()
        spk_rec, mem_rec = forward_pass(net, num_steps, data)

        # initialize the loss & sum over time
        loss_val = torch.zeros((1), dtype=dtype, device=device)
        for step in range(num_steps):
            loss_val += loss(mem_rec[step], targets)

        # Gradient calculation + weight update
        optimizer.zero_grad()
        loss_val.backward()
        optimizer.step()

        # Store loss history for future plotting
        loss_hist.append(loss_val.item())

        # utils.reset(net)

        # Test set
        with torch.no_grad():
            net.eval()
            test_data, test_targets = next(iter(test_loader))
            test_data = test_data.to(device)
            test_data = test_data.reshape(data.size(0), data.size(1), 2, -1).type(torch.float)
            test_data = torch.sign(test_data)
            test_targets = test_targets.to(device)

            # Test set forward pass
            test_spk_rec, test_mem_rec = forward_pass(net, num_steps, test_data)

            # Test set loss
            test_loss = torch.zeros((1), dtype=dtype, device=device)
            for step in range(num_steps):
                test_loss += loss(test_mem_rec[step], test_targets)
            test_loss_hist.append(test_loss.item())

            # Print train/test loss/accuracy
            if counter % 50 == 0:
                train_printer()
            counter += 1
            iter_counter +=1

# training_times = np.array(training_times)
# print(f"Mean training time: {training_times.mean():.2f} seconds")
# print(f"Standard deviation: {training_times.std():.2f} seconds")

"""If this was your first time training an SNN, then congratulations!

# 8. Results
## 8.1 Plot Training/Test Loss
"""

# Plot Loss
fig = plt.figure(facecolor="w", figsize=(10, 5))
#print the avg losses per epoch
loss_hist = np.array(loss_hist)
test_loss_hist = np.array(test_loss_hist)

# iter_per_epoch = loss_hist.size // num_epochs

loss_hist_avg = np.mean(loss_hist.reshape(num_epochs, -1), axis=1)
test_loss_hist_avg = np.mean(test_loss_hist.reshape(num_epochs, -1), axis=1)

plt.plot(loss_hist_avg)
plt.plot(test_loss_hist_avg)
plt.title("Loss Curves")
plt.legend(["Train Loss", "Test Loss"])
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

"""The loss curves are noisy because the losses are tracked at every iteration, rather than averaging across multiple iterations.

## 8.2 Test Set Accuracy
This function iterates over all minibatches to obtain a measure of accuracy over the full 10,000 samples in the test set.
"""

total = 0
correct = 0

# drop_last switched to False to keep all samples
#test_loader = DataLoader(train_set, batch_size=1, shuffle=True, drop_last=False)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, collate_fn=tonic.collation.PadTensors(batch_first=False), drop_last=True)
test_batch = iter(test_loader)


with torch.no_grad():
  net.eval()
  for test_data, test_targets in test_batch:
    test_data = test_data.to(device)
    test_data = test_data.reshape(test_data.size(0), test_data.size(1), test_data.size(2), -1).type(torch.float)
    test_data = torch.sign(test_data)
    test_targets = test_targets.to(device)

    # Test set forward pass
    test_spk_rec, test_mem_rec = forward_pass(net, num_steps, test_data)

    _, predicted = test_spk_rec.sum(dim=0).max(1)
    total += targets.size(0)
    correct += (predicted == test_targets).sum().item()

print(f"Total correctly classified test set images: {correct}/{total}")
print(f"Test Set Accuracy: {100 * correct / total:.2f}%")

# total = 0
# correct = 0

# #REFERENCE
# #https://deci.ai/blog/measure-inference-time-deep-neural-networks/
# # drop_last switched to False to keep all samples
# test_loader = DataLoader(mnist_test, batch_size=1, shuffle=True, drop_last=True)


# # INIT LOGGERS
# starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
# repetitions = 1
# timings=np.zeros((repetitions,1))

# # MEASURE PERFORMANCE
# with torch.no_grad():
#   for rep in range(repetitions):
#     net.eval()
#     for data, targets in test_loader:
#       data = data.to(device)
#       data = spikegen.rate(data, num_steps=num_steps).to(device)
#       targets = targets.to(device)
#       # forward pass
#       starter.record()
#       test_spk, _ = net(data.view(num_steps,1, -1))
#       ender.record()
#       # WAIT FOR GPU SYNC
#       torch.cuda.synchronize()
#       curr_time = starter.elapsed_time(ender)
#       timings[rep] = curr_time
#       _, predicted = test_spk.sum(dim=0).max(1)
#       total += targets.size(0)
#       correct += (predicted == targets).sum().item()

# # calculate total accuracy
# print(f"Total correctly classified test set images: {correct}/{total}")
# print(f"Test Set Accuracy: {100 * correct / total:.2f}%")
# print("-------------------------------------------------")

# mean_syn = np.sum(timings) / repetitions
# std_syn = np.std(timings)
# print(mean_syn)

"""# SAVE WEIGHTS

"""

torch.save(net.state_dict(), "trained_snn_n-mnist_weights_only.pt")
#torch_input = torch.randn(1, 784).to(device)
#onnx_program = torch.onnx.dynamo_export(net, torch_input)
#onnx_program.save("snn_snnTorch_Leaky.onnx")
# net.state_dict
# np.save("weights_0_nvidia_gtx1050", net.state_dict()["0.weight"].cpu().numpy())
# np.save("weights_1_nvidia_gtx1050", net.state_dict()["2.weight"].cpu().numpy())
# np.save("weights_2_nvidia_gtx1050", net.state_dict()["4.weight"].cpu().numpy())

"""# SAVE DATASET"""

#get all data from test_set as a single tensor
test_loader = DataLoader(test_set, batch_size=1, shuffle=True, collate_fn=tonic.collation.PadTensors(batch_first=False), drop_last=False)
test_data = []
test_targets = []
for data, targets in test_loader:
    test_data.append(data)
    test_targets.append(targets)
test_data = torch.cat(test_data, dim=0)
test_targets = torch.cat(test_targets, dim=0)
test_data = test_data
test_data = test_data.reshape(test_data.size(0), test_data.size(1), test_data.size(2), -1).type(torch.float)
test_data = torch.sign(test_data)

with open('n-mnist_testset_data.txt', 'w') as f:
    for i in range(test_data.size(0)):
        for j in range(test_data.size(1)):
            for k in range(test_data.size(2)):
                for l in range(test_data.size(3)):
                    f.write(str(int(test_data[i][j][k][l].item())))
                    f.write(' ')
                f.write('\n')


with open('n-mnist_testset_targets.txt', 'w') as f:
    for i in range(test_targets.size(0)):
        f.write(str(test_targets[i].item()))
        f.write('\n')

net.load_state_dict(torch.load("trained_snn_n-mnist_weights_only.pt"))

# save the weights as a C header file
with open('n-mnist_weights.h', 'w') as f:
    f.write('#ifndef N_MNIST_WEIGHTS_H\n')
    f.write('#define N_MNIST_WEIGHTS_H\n')
    f.write(f'weight_t weights_0[{num_hidden}][{num_inputs}] = {{')
    for i in range(num_hidden):
        f.write('{')
        for j in range(num_inputs):
            f.write(str(net.state_dict()["0.weight"][i][j].item()))
            if j != num_inputs - 1:
                f.write(',')
        f.write('}\n')
        if i != num_hidden - 1:
            f.write(',')
    f.write('};')
    f.write(f'\nweight_t weights_1[{num_outputs}][{num_hidden}] = {{')
    for i in range(num_outputs):
        f.write('{')
        for j in range(num_hidden):
            f.write(str(net.state_dict()["2.weight"][i][j].item()))
            if j != num_hidden - 1:
                f.write(',')
        f.write('}\n')
        if i != num_outputs - 1:
            f.write(',')
    f.write('};')
    f.write(f'\n#endif // N_MNIST_WEIGHTS_H\n')

#print min max weights
print(f"Min weight 0: {net.state_dict()['0.weight'].min()}")
print(f"Max weight 0: {net.state_dict()['0.weight'].max()}")
print(f"Min weight 1: {net.state_dict()['2.weight'].min()}")
print(f"Max weight 1: {net.state_dict()['2.weight'].max()}")

!pip install nir

!pip install nirtorch

# export model as nir
from snntorch.export_nir import export_to_nir
sample_data = torch.randn(1, num_inputs)
nir_graph = export_to_nir(net, sample_data, model_name="snntorch")

import nir
nir.write(nir_graph, "ecg_data_ptbdb_SNN.nir")

# Apply dynamic quantization to the model
#quantized_model = torch.quantization.quantize_dynamic(
#    net, {torch.nn.Linear}, dtype=torch.qint8
#)

# # Define dummy input for the model
# dummy_input = torch.randn(1, 784)

# # Export the quantized model to ONNX
# onnx_model_path = "quantized_snn.onnx"
# torch.onnx.export(
#     quantized_model,           # Model to export
#     dummy_input,               # Example input
#     onnx_model_path,           # Path to save the ONNX model
#     export_params=True,        # Export model parameters
#     opset_version=13,          # ONNX opset version
#     # input_names=['input'],     # Input names
#     # output_names=['output'],   # Output names
#     # dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # Optional dynamic axes
# )

"""# LOAD DATA"""

# total_samples = 0
# total_time = 0

# test_loader = DataLoader(mnist_test, batch_size=1, shuffle=True, drop_last=True)

# with torch.no_grad():
#       for data, targets in test_loader:
#         data = spikegen.rate(data, num_steps=num_steps).to(device)
#         data = data.view(num_steps, 1, -1)
#         starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
#         starter.record()
#         _ = net(data)
#         ender.record()
#         torch.cuda.synchronize()
#         curr_time = starter.elapsed_time(ender)/1000
#         total_time += curr_time
#         total_samples += 1
# Throughput = (total_samples)/total_time
# print('Final Throughput:',Throughput)

# train_loader = DataLoader(mnist_train, batch_size=1, shuffle=True, drop_last=False)
# test_loader = DataLoader(mnist_test, batch_size=1, shuffle=True, drop_last=False)

# data_test, target_test = [], []
# for data, target in test_loader:
#     data_test.append(data)
#     target_test.append(target)

# data_test = torch.cat(data_test).squeeze()
# target_test = torch.cat(target_test)

# print(data_test.size())
# print(target_test.size())

# # Load MNIST dataset

# data_tensor, targets_tensor = [], []

# with open("data_test.txt", 'w') as df, open("targets_test.txt", 'w') as tf:
#   num_steps = 25
#   for data, targets in test_loader:
#     data = data
#     data = spikegen.rate(data, num_steps=num_steps)
#     data = data.view(num_steps, -1)
#     data_tensor.append(data)                          # to saved as Tensor
#     targets_tensor.append(targets)                    # to saved as Tensor
#     for d in data:
#       df.writelines(''.join([str(int(i)) for i in d.tolist()]) + '\n')
#       tf.writelines(str(int(targets)) + '\n')

# data_tensor = torch.stack(data_tensor,)                 # convert to Tensor
# targets_tensor = torch.stack(targets_tensor).squeeze()  # convert to Tensor

# torch.save(data_tensor, "data_test.pt")
# torch.save(targets_tensor, "targets_test.pt")

# data_test_samples = []
# targets_test_samples = []
# with open("data_test_samples.txt", 'w') as df, open("targets_test_samples.txt", 'w') as tf:
#   num_steps = 25
#   indexes = [0,1,2,3,4,5,6,7,8,9]*100
#   count = 0
#   while count < len(indexes):
#     data, targets = next(iter(test_loader))
#     while int(targets) != indexes[count]:
#       data, targets = next(iter(test_loader))
#     count += 1
#     data = data
#     data = spikegen.rate(data, num_steps=num_steps)
#     data = data.view(num_steps, -1)
#     data_test_samples.append(data)
#     targets_test_samples.append(targets)
#     for d in data:
#       df.writelines(''.join([str(int(i)) for i in d.tolist()]) + '\n')
#       tf.writelines(str(int(targets)) + '\n')

# data_test_samples = torch.stack(data_test_samples)                 # convert to Tensor
# targets_test_samples = torch.stack(targets_test_samples).squeeze()  # convert to Tensor

# torch.save(data_test_samples, "data_test_samples.pt")
# torch.save(targets_test_samples, "targets_test_samples.pt")

# data_test_samples = [d.numpy() for d in data_test_samples]

# data_test_samples = np.array(data_test_samples)

# data_test_samples.shape

# data_test_samples = [d.reshape(25, 1, 784) for d in data_test_samples]

# data_test_samples = torch.Tensor(data_test_samples)

# data_test_samples = data_test_samples.to(device)

# spikes = []

# for i in range(data_test_samples.size(0)):
#     spk, mem = net(data_test_samples[i])
#     spikes.append(spk)

# spikes = [s.cpu().tolist() for s in spikes]

# spikes = np.array(spikes)

# with open("outputs_test_samples_gtx_1050.txt", 'w') as f:
#     for i in range(spikes.shape[0]):
#         for j in range(spikes.shape[1]):
#             f.writelines(''.join([str(int(s)) for s in spikes[i, j, 1]]) + '\n')

# model = EfficientNet.from_pretrained('efficientnet-b0')
# device = torch.device("cuda")
# model.to(device)
# dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)

# # INIT LOGGERS
# starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)
# repetitions = 300
# timings=np.zeros((repetitions,1))
# #GPU-WARM-UP
# for _ in range(10):
#     _ = model(dummy_input)
# # MEASURE PERFORMANCE
# with torch.no_grad():
#     for rep in range(repetitions):
#         starter.record()
#         _ = model(dummy_input)
#         ender.record()
#         # WAIT FOR GPU SYNC
#         torch.cuda.synchronize()
#         curr_time = starter.elapsed_time(ender)
#         timings[rep] = curr_time

# mean_syn = np.sum(timings) / repetitions
# std_syn = np.std(timings)
# print(mean_syn)

"""Voila! That's it for static MNIST. Feel free to tweak the network parameters, hyperparameters, decay rate, using a learning rate scheduler etc. to see if you can improve the network performance.

# Conclusion
Now you know how to construct and train a fully-connected network on a static dataset. The spiking neurons can also be adapted to other layer types, including convolutions and skip connections. Armed with this knowledge, you should now be able to build many different types of SNNs. [In the next tutorial](https://snntorch.readthedocs.io/en/latest/tutorials/index.html), you will learn how to train a spiking convolutional network, and simplify the amount of code required using the `snn.backprop` module.

Also, a special thanks to Bugra Kaytanli for providing valuable feedback on the tutorial.

If you like this project, please consider starring ⭐ the repo on GitHub as it is the easiest and best way to support it.

# Additional Resources

* [Check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)
"""